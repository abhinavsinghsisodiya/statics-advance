{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qln-vyiBhQ-t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistics Advance Part 1"
      ],
      "metadata": {
        "id": "4Gv6bgjbjg1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a random variable in probability theory\n",
        "-; In probability theory, a random variable is a function that assigns a numerical value to each outcome of a random experiment. It's essentially a variable whose value is a numerical outcome of a random phenomenon. These variables can be either discrete or continuous, depending on whether the outcomes can be counted or measured on a continuous scale.\n",
        "\n",
        "\n",
        "2.  What are the types of random variables\n",
        "-;\n",
        "Random variables are classified into discrete and continuous variables. The main difference between the two categories is the type of possible values that each variable can take.\n",
        "\n",
        "\n",
        "3.What is the difference between discrete and continuous distributions\n",
        "-; In probability and statistics, the key difference between discrete and continuous distributions lies in the nature of their possible values. Discrete distributions have a finite or countably infinite number of distinct values, while continuous distributions can take on any value within a given range\n",
        "\n",
        "\n",
        "4. What are probability distribution functions (PDF)\n",
        "-;A probability distribution is a mathematical function that describes the probability of different possible values of a variable. Probability distributions are often depicted using graphs or probability tables.\n",
        "\n",
        "\n",
        "5. How do cumulative distribution functions (CDF) differ from probability distribution functions (PDF)\n",
        "-; What are the key differences between PDF and CDF? The probability distribution function (PDF) gives the probability that a random variable takes on a specific value, while the cumulative distribution function (CDF) gives the probability that a random variable is less than or equal to a certain value\n",
        "\n",
        "\n",
        "6. What is a discrete uniform distribution\n",
        "-;A discrete uniform distribution is one that has a finite (or countably finite) number of random variables that have an equally likely chance of occurring. Examples of experiments that result in discrete uniform distributions are the rolling of a die or the selection of a card from a standard deck. For a fair, six-sided die, there is an equal probability (1/6) of rolling a 1, 2, 3, 4, 5, or 6. Similarly, a standard deck of cards has 52 different cards, so the probability of selecting any one card is 1/52. Also, in both cases, there are distinct outcomes (dice roll or cards), indicating the discrete nature of the events.\n",
        "\n",
        "\n",
        "7. What are the key properties of a Bernoulli distribution\n",
        "-;The Bernoulli distribution is a discrete probability distribution describing the probability of success or failure in a single experiment with two possible outcomes. Key properties include a single parameter (p), representing the probability of success, independent trials, and a memoryless characteristic, meaning the outcome of one trial doesn't affect others.\n",
        "\n",
        "\n",
        "\n",
        "8.  What is the binomial distribution, and how is it used in probability\n",
        "-; The binomial distribution is a probability distribution that models the probability of a certain number of successes in a fixed number of independent trials, where each trial has only two possible outcomes: success or failure. It's used in probability to calculate the likelihood of observing a specific number of successes in a series of independent events, like coin flips or yes/no questions.\n",
        "\n",
        "\n",
        "\n",
        "9.  What is the Poisson distribution and where is it applied\n",
        "-; The Poisson distribution is a statistical tool used to model the probability of a certain number of events happening within a fixed interval of time or space when those events occur randomly and independently of each other at a constant average rate. It's essentially a discrete probability distribution that tells you how many times you're likely to see an event occur given its average rate of occurrence.\n",
        "Applications:\n",
        "Call Center Modeling: Predicting the number of phone calls a call center receives in a specific time period.\n",
        "Customer Arrivals: Modeling the number of customers arriving at a store or restaurant within a given timeframe.\n",
        "Radioactive Decay: Modeling the number of radioactive decays in a sample.\n",
        "Mutation Rates: Determining the probability of mutations in a large population of cells.\n",
        "Quality Control: Analyzing the number of defects in manufactured items.\n",
        "Traffic Analysis:\n",
        "\n",
        "\n",
        "\n",
        "10. What is a continuous uniform distribution\n",
        "-;The continuous uniform distribution is such that the random variable X takes values between a (lower limit) and b (upper limit). In the field of statistics, a and b are known as the parameters of continuous uniform distribution. We cannot have an outcome of either less than a or greater than b\n",
        "\n",
        "\n",
        "11. What are the characteristics of a normal distribution\n",
        "-;Properties of the Normal distribution | CFA Level 1A normal distribution, also known as a Gaussian distribution, is a continuous probability distribution characterized by its bell-shaped curve and symmetry around its mean. Key features include the mean, median, and mode being equal, and the distribution being symmetrical about the mean. The area under the curve is 1, and the tails of the distribution approach, but never touch, the x-axis.\n",
        "Normal distributions are symmetric, unimodal, and asymptotic, and the mean, median, and mode are all equal. A normal distribution is perfectly symmetrical around its center. That is, the right side of the center is a mirror image of the left side. There is also only one mode, or peak, in a normal distribution.\n",
        "\n",
        "\n",
        "12.  What is the Central Limit Theorem (CLT), and why is it critical in statistics\n",
        "-;The Central Limit Theorem (CLT) is a fundamental statistical concept stating that the distribution of the sample means will approach a normal distribution as the sample size increases, regardless of the original population's distribution. It's critical in statistics because it allows for the use of statistical tests and procedures that rely on the normal distribution, even when dealing with data that doesn't follow a normal distribution.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "13.  How does the Central Limit Theorem relate to the normal distribution\n",
        "-;The Central Limit Theorem (CLT) establishes a crucial link between the normal distribution and the sampling distribution of the mean. Specifically, the CLT states that as the sample size increases, the distribution of sample means will approximate a normal distribution, regardless of the original population's distribution. This means that even if your data doesn't come from a normal distribution, the average of many samples from it will, in many cases, follow a normal distributio\n",
        "The central limit theorem states that if you take sufficiently large samples from a population, the samples' means will be normally distributed, even if the population isn't normally distributed\n",
        "\n",
        "\n",
        "\n",
        "14.  What is the application of Z statistics in hypothesis testing9\n",
        "-;Z-statistics are used in hypothesis testing to determine if there's a statistically significant difference between a sample mean and a population mean, or between two sample means. They are particularly useful when the population standard deviation is known or the sample size is large (n ≥ 30).\n",
        "Applications in Hypothesis Testing:\n",
        "1. Comparing Sample Mean to Population Mean:\n",
        "Z-tests can assess if a sample's mean is significantly different from a known population mean.\n",
        "2. Comparing Two Sample Means:\n",
        "They can determine if there's a significant difference between the means of two independent samples.\n",
        "3. Comparing Sample Proportion to Population Proportion:\n",
        "Z-tests can also be used to compare the proportion of a characteristic in a sample to an assumed proportion in the population.\n",
        "4. Comparing Proportions in Two Samples:\n",
        "They can be used to assess if there's a significant difference in proportions between two samples.\n",
        "5. Large Sample Sizes:\n",
        "When dealing with large sample sizes (n ≥ 30), Z-tests are a reliable way to test hypotheses about population means and proportions, even if the population standard deviation is unknown.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "15.  How do you calculate a Z-score, and what does it represent\n",
        "-;A z-score (also called a standard score) represents how many standard deviations a particular data point is away from the mean (average) of a dataset. It's calculated using a formula and tells you the relative position of a data point within its distribution.\n",
        "The formula for calculating a z-score is z = (x-μ)/σ, where x is the raw score, μ is the population mean, and σ is the population standard deviation. As the formula shows, the z-score is simply the raw score minus the population mean, divided by the population standard deviation\n",
        "\n",
        "\n",
        "16. What is the standard normal distribution, and why is it important\n",
        "-;The standard normal distribution is a specific type of normal distribution with a mean of 0 and a standard deviation of 1. It's a crucial tool in statistics because any normal distribution can be converted to the standard normal distribution, making it easier to calculate probabilities and compare datasets.\n",
        "\n",
        "\n",
        "\n",
        "17.What are point estimates and interval estimates in statistics\n",
        "-;In statistics, point estimates offer a single value as the best guess for a population parameter, while interval estimates provide a range of values within which the parameter is likely to fall. Point estimates are simple and easy to understand, but they don't account for uncertainty. Interval estimates, like confidence intervals, offer a range and a level of confidence that the true value lies within that range.\n",
        "Point Estimates:\n",
        "A single value used to estimate a population parameter.\n",
        "For example, the sample mean is a point estimate of the population mean.\n",
        "While easy to calculate and communicate, point estimates don't offer a measure of the uncertainty of the estimate.\n",
        "Interval Estimates:\n",
        "A range of values within which the population parameter is likely to fall.\n",
        "Confidence intervals are a common type of interval estimate.\n",
        "Provide a level of confidence that the true population parameter lies within the calculated interval.\n",
        "Offer a more comprehensive representation of the parameter and its uncertainty compared to point estimates.\n",
        "\n",
        "\n",
        "\n",
        "18. What is the significance of confidence intervals in statistical analysis\n",
        "-; Confidence intervals are crucial in statistical analysis as they provide a range of plausible values for an unknown population parameter, giving a more informative picture than just a single point estimate. They help assess the precision of an estimate and determine the statistical significance of results.\n",
        "\n",
        "\n",
        "19. What is the relationship between a Z-score and a confidence interval\n",
        "-;A Z-score and a confidence interval are related through the concept of the standard normal distribution and the margin of error. A Z-score represents how many standard deviations a data point is from the mean in a normal distribution. Confidence intervals, on the other hand, are ranges of values that likely contain the true population parameter with a certain level of confidence. The Z-score is used to calculate the margin of error, which defines the width of the confidence interval.\n",
        "\n",
        "\n",
        "20.  How are Z-scores used to compare different distributions\n",
        "-;Z-scores are used to compare different distributions by standardizing data points to a common scale. This allows for meaningful comparisons of values even when the original datasets have different means and standard deviations. By converting data to a standard normal distribution (where the mean is 0 and the standard deviation is 1), Z-scores reveal how many standard deviations a data point is away from the mean.\n",
        "\n",
        "\n",
        "21. What are the assumptions for applying the Central Limit Theorem\n",
        "-;The Central Limit Theorem (CLT) relies on a few key assumptions for its validity, mainly concerning sampling methods and sample size. These assumptions are: independent and identically distributed (i.i.d.) samples, a sufficiently large sample size (typically 30 or more), and a population with a finite variance\n",
        "Assumptions Behind the Central Limit Theorem\n",
        "It needs to be sampled at random. The samples should be unrelated to one another. One sample should not impact the others. When taking samples without replacement, the sample size should not exceed 10% of the population.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "22.  What is the concept of expected value in a probability distribution\n",
        "-;In a probability distribution, the expected value (also known as the mean or average) is the weighted average of all possible outcomes of a random variable, where each outcome is weighted by its probability of occurrence. It represents the long-term average you'd expect to observe if you repeated the experiment many times.\n",
        "\n",
        "\n",
        "23. How does a probability distribution relate to the expected outcome of a random variable\n",
        "-;A probability distribution describes the likelihood of different outcomes for a random variable. The expected outcome, or expected value, is a weighted average of all possible outcomes, where the weights are the probabilities from the distribution. Essentially, the probability distribution provides the context for calculating the expected outcome by weighting each possible value of the random variable by its probability of occurrence\n",
        "\n"
      ],
      "metadata": {
        "id": "ste_hM1Tjlgd"
      }
    }
  ]
}